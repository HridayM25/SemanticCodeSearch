{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "436deb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5279696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hrida\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.51.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hrida\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.13.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "575e598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "251aaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "ctokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "cmodel = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "076297be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_embeddings(code_snippet, tokenizer=ctokenizer, model=cmodel):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Returns a vector of shape (1,768) resembling the embedding of the code provided\n",
    "    \n",
    "    Input : Code in Text\n",
    "    Return : Tensor\n",
    "    \n",
    "    \"\"\"\n",
    "    code_tokens=tokenizer.tokenize(code_snippet)\n",
    "    tokens=[tokenizer.cls_token]+[tokenizer.sep_token]+code_tokens+[tokenizer.eos_token]\n",
    "    tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "    tokens_ids = tokens_ids[:500]\n",
    "    context_embeddings=model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "    code_embedding = context_embeddings[:, 0, :]\n",
    "    return code_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "838bf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nl_embeddings(text, model_nl=sbert_model):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Returns a vector of size (1,768) that corresponds to the embedding of the text\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return torch.from_numpy(model_nl.encode(text).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "af908455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "84751fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=get_code_embeddings(\"def func(): return 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "936d26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = get_nl_embeddings(\"Hello I am a boy\")\n",
    "#q1=q1.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "eb102912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fe568cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model Architecture is LinearNetwork(\n",
      "  (input_layer): Linear(in_features=768, out_features=1024, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0-6): 7 x Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=1024, out_features=768, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNetwork, self).__init__()\n",
    "        self.input_layer = nn.Linear(768,1024)\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(1024,1024) for _ in range(7)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(1024, 768)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = torch.relu(hidden_layer(x))\n",
    "        x = self.tanh(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "model = LinearNetwork()\n",
    "\n",
    "print(\"The Model Architecture is\", str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8140f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SemanticLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        cos = nn.CosineSimilarity()\n",
    "        loss = 1 - cos(inputs,targets)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "28bdb0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_suitable(text):\n",
    "    text=text.replace(\"\\n\", \",\")\n",
    "    text=text.replace(\".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "820c5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "627586da",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3a6a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "op=model(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pair import cosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "818e44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SemanticLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e825ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=loss(op,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37dbeb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90094a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "jsonObj = pd.read_json(path_or_buf='python_train_0.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "643893e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "code=jsonObj.code_tokens\n",
    "string=jsonObj.docstring_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "066f8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3a554034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def predict ( X_img_path  knn_clf = None  model_path = None  distance_threshold = 06 ) : if not os  path  isfile ( X_img_path ) or os  path  splitext ( X_img_path ) [ 1 ] [ 1 : ] not in ALLOWED_EXTENSIONS : raise Exception ( \"Invalid image path: {}\"  format ( X_img_path ) ) if knn_clf is None and model_path is None : raise Exception ( \"Must supply knn classifier either thourgh knn_clf or model_path\" ) # Load a trained KNN model (if one was passed in) if knn_clf is None : with open ( model_path  \\'rb\\' ) as f : knn_clf = pickle  load ( f ) # Load image file and find face locations X_img = face_recognition  load_image_file ( X_img_path ) X_face_locations = face_recognition  face_locations ( X_img ) # If no faces are found in the image return an empty result if len ( X_face_locations ) == 0 : return [ ] # Find encodings for faces in the test iamge faces_encodings = face_recognition  face_encodings ( X_img  known_face_locations = X_face_locations ) # Use the KNN model to find the best matches for the test face closest_distances = knn_clf  kneighbors ( faces_encodings  n_neighbors = 1 ) are_matches = [ closest_distances [ 0 ] [ i ] [ 0 ] <= distance_threshold for i in range ( len ( X_face_locations ) ) ] # Predict classes and remove classifications that aren\\'t within the threshold return [ ( pred  loc ) if rec else ( \"unknown\"  loc ) for pred  loc  rec in zip ( knn_clf  predict ( faces_encodings )  X_face_locations  are_matches ) ] '"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f63a62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_tokens=tokenizer.tokenize(code[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4c64b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence(doc_tokens):\n",
    "    text=\"\"\n",
    "    for token in doc_tokens:\n",
    "        text +=token + \" \"\n",
    "    text=text.replace(\".\", \"\")\n",
    "    text=text.replace(\",\" , \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4bc36d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=string.apply(make_sentence)\n",
    "code=code.apply(make_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "07d72504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elapsed time was 32.7270290851593 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "string_set1.apply(get_nl_embeddings)\n",
    "end=time.time()\n",
    "print(f\"The elapsed time was {end-start} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9f609dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_set1= string[:100]\n",
    "code_set1 = code[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "end=time.time()\n",
    "print(f\"The elapsed time was {end-start} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
